
\chapter{A generic sound processing library}

\epigraph{Numbers it is. All music when you come to think.  Two
  multiplied by two divided by half is twice one.  Vibrations: chords
  those are. One plus two plus six is seven. Do anything you like with
  figures juggling. Always find out this equal to that. Symmetry under
  a cemetery wall. He doesn’t see my mourning. Callous: all for his
  own gut. Musemathematics. And you think you’re listening to the
  etherial. But suppose you said it like: Martha, seven times nine
  minus $x$ is thirtyfive thousand.  Fall quite flat. It’s on account of
  the sounds it is.}{\emph{Ulysses}\\\textsc{James Joyce}}

\todo{Este capítulo en general necesita más dibujos.}

\section{Analysis}

Requirements \ref{req:iter1-begin} to \ref{req:iter1-end} and
\ref{req:iter1-begin2} to \ref{req:iter1-end2} refer to the second
layer of our system --- in a bottom-up approach. The most crucial
question here: how do we represent a sound in a computer? Then, a new
question arises: how do we get the sound to the speakers? The later
question has a trivial answer --- use whatever API your operating
system exposes for delivering sound to the soundcard --- but the first
question is still to be answered. Actually, the solution to this first
question mostly subsumes the issue of how to interface with these
external interfaces, thus, shall we debate it with care.

\subsection{Factors of sound representation}
\todo{Me he dado cuenta de que esta sección introduce muchas
  definiciones. ¿Tal vez utilizar un estilo más formal usando el
  paquete theorem para las definiciones ayudaría a usar el documento
  como referencia?}

A sound signal is a longitudinal wave of air in motion. We can
analogically record the \emph{proximal stimuli} --- i.e. the physical
stimuli leading to the subjective act of perception
\cite{goldstein01sensation} --- sound by measuring the successive
oscillating values of air pressure in the observer's point in
space. Note that an static air pressure value can not be perceived and
the sensation of sound is caused by the relative oscillation of this
measure. The \emph{amplitude} of this change is associated to our
perception of \emph{loudness}, the frequency of this oscillation
mostly logarithmically determines our perception of pitch. We phrased
this conditionally because these two variables are actually
interrelated and our actual subjective perception of loudness might
vary with pitch and otherwise \cite{fletcher37loudness}.

Most of the time, we represent the relative air pressure value as a
voltage, that varies at some range --- p.e. $[ -5, 5 ] V$. This is an
analogous signal that we have to discretise somehow in order to
manipulate it computationally.

\subsubsection{Temporal quantisation}

Temporal quantisation relates to how many times per second do we store
the current voltage or air pressure value. The value of the signal
between to equally spaced in time samples is unknown, but we can use
some interpolation method to \emph{upsample} a signal --- i.e. to
figure out what is between two samples. Most of the time we refer to
the \emph{sampling rate}, in hertz, as the frequency of the temporal
quantisation.

We know from \emph{Niquist-Shannon sampling theorem} that perfect
reconstruction of a signal is possible when the sampling frequency is
greater than twice the maximum frequency of the signal being sampled,
or equivalently, when the \emph{Nyquist frequency} (half the sample
rate) exceeds the highest frequency of the signal being
sampled. Because the hearing range in most human beings is 20 Hz--20
kHz, audio compact discs use a 44.1 kHz sampling rate. Other popular
rates in audio production are 48 kHz, 96 kHz and 192 kHz. Sampling
rates bellow 44.1 kHz are used also in old computer games that were
limited by the computing power and low bandwidth systems such as
telephone, where low cost and proper understanding of human speech is
more important than audio fidelity.

The sound representation mechanism itself does not vary with the
sampling rate, and thus supporting various rates depends more on the
implementation of the signal processing units and the overall
performance of the system, with the CPU being able to process so many
samples per second being the biggest constraint.

\subsubsection{Spatial quantisation}

Spatial quantisation determines how many possible values can a sample
take in our finite and discrete scale. In a computer system, this is
determined by the size in bits of the underlying type used to store
the samples. An audio CD uses a \emph{bitdepth} of 16 bit with samples
that can take $65.536$ possible values while professional audio uses 24
bit or 32 bit samples. We can even see systems using 64 bit samples
during the processing to avoid accumulative rounding problems due to
heavy arithmetic. The \emph{dynamic range} of a signal with $Q$-bits
quantisation is:
\begin{equation}
  \mathrm{DR_{ADC}} = 20 \times \log_{10}(2^Q) = (6.02 \cdot Q)\, \mathrm{dB}
\end{equation}
The maximum \emph{signal-to-noise} ratio for such a system is:
\begin{equation}
  \mathrm{SNR_{ADC}} =  \left (1.76 + 6.02 \cdot Q \right )\ \mathrm{dB}
\end{equation}

Most analog systems are said to have a dynamic range of around 80 dB
\cite{fries05digital}. Digital audio CD have a theoretical
dynamic range of 96 db --- actual value is around 90 db due to
processing. Human hearing pain level is at 135 db but actually
prolonged exposure to such loud sound can cause damage. A loud rock
concert is around 120 dB and a classical music performance is at
110 db \cite{ludwig09music}, thus requiring bitdepth of at least 24
bit (theoretical dynamic range of 144 dB) for perfect fidelity.

There are some other aspects related to representation of samples in a
computer, such as the \emph{signedness} of the underlying type. Signed
types are usually considered more convenient for audio signals as 0
can be easily recognised as the still no-sound value simplifying
computations. Another important factor is whether we use \emph{fixed
  point} or \emph{floating point} arithmetic. While fixed point is
used in low-cost DSP hardware, floating point is the most common
representation in current audio software as nowadays processors are
optimised for SIMD\footnote{Single Instruction Multimple Data, as
  supported by MMX, 3D Now! and SSE extensions in Intel and AMD chips}
floating point arithmetic. Moreover, the algorithms implementation is
much harder to encode because products produce greater values and
there are many ways on how to account the carry.  Actually, even while
the actual bitdepth (the bit for the mantissa) of a 32 bit floating
point is the same of a 24 bit fixed point, then a 32 bit fixed point
will have a quite lower \emph{quantization error}, but the dynamic
range and SNR of a floating point is much higher because the
values are spaced logarithmically over a huge range
\cite{smith02dsp}. Another factor is the \emph{endianess} of fixed
point values but is relevant only when interfacing with file formats
and output devices.

\subsubsection{Channel space}

Because our hearing system is dicotomically symmetric, audio
engineers discovered that much better fidelity can be achieved by
reproducing the sound with some differences from two separate
loudspeakers. This is the well-known \emph{stereophonic} sound,
commonly named just \emph{stereo}.

For representing such a signal, two different streams of information
are needed for the left and right channels. Moreover, nowdays
\emph{quadraphonic}, and \emph{surround} sound with varying numbers of
channels up to 20.2 are used in different systems.

We call \emph{channel space} to the set of semantic channels we use in
some sort of audio representation --- p.e. stereo audio has channel
space with $left$ and $right$ elements. We use the term
\emph{frame} to call a set of samples coincident in time, this is, the
samples of the various channels at a given time point. Thus, we will
use most of the time the more accurate term \emph{frame rate}.

This rises the problem on how to linearise the multi channel data. The
most common mechanism in domestic hardware is by \emph{interleaving}
the samples of different channels, this is, by storing the frames
sequentially. However, high-end hardware often accepts data in
non-interleaved form where the samples of each channel is stored in a
separate sequence. In this document, we borrow from the image
processing world the term \emph{planar} to refer to non-interleaved
data. Software doing a lot of processing of the audio signal often
chooses this representation as it is easier to scale to varying number
of channels and split the signal to do per-channel filtering. Figure
\ref{fig:interleaving} compares visually the interleaved and planar
formats.

\begin{figure}[h]
  \centering
  \subfloat[]{\includegraphics[width=2in]{pic/fmt-planar.png}}\;
  \subfloat[]{\includegraphics[width=3in]{pic/fmt-interleaved.png}}
  \caption{Multi-channal data in planar (a) and interleaved (b) form.}
  \label{fig:interleaving}
\end{figure}

Another issue is the order in which the data from different semantic
channels is stored. We call a \emph{channel layout} a bijection $L : C
\rightarrow \mathbb{Z}_{\|C\|}$, where $C$ is a given \emph{channel
  space}. For example, the mapping $\{ left
\mapsto 0, right \mapsto 1 \}$ is a common layout for stereo sound,
but $\{ left \mapsto 1, right \mapsto 0 \}$ is sometimes used too.

\subsection{Common solutions}

As we have already noticed, 32 bit floating point sound with planar
left-right layout the most common in software of our kind during
internal processing. As most of this software is written in C, a
simple \texttt{float**} does the job. This was, actually, the internal
representation used in GNU Psychosynth in versions prior to 0.2.0,
wrapped in the \texttt{audio\_buffer} class.

However, this design starts to wobble whenever one has to interface
with some other library or hardware using a different format. Thus,
the \texttt{audio\_buffer} class provided different
\texttt{interleave\_*} and \texttt{deinterleave\_*}, where the
asterisk can be substituted by different sample formats like
\texttt{s16} or \texttt{s32} (fixed point signed 16 bit and 32 bit
respectively). This is very inconvenient because, as we have seen
through this section, many orthogonal factor affect audio
representation inducing a combinatorial explosion of format conversion
functions. Take a look at the 64 different read and write functions in
the \texttt{pcm.c} file of the
LibSndfile\footnote{\url{http://www.mega-nerd.com/libsndfile/}}
library.

This is a maintenance hell, but using the common means for abstracting
orthogonal behaviour variability, i.e. dynamic polymorphism, is simply
not an option in any audio software which supports real-time operation.

\subsection{A generic approach: Boost.GIL}

However, there is a piece of software that proved that this issue can be
solved in C++ using static polymorphism. This is the Generic
Image Library\footnote{http://stlab.adobe.com/gil} which was developed
by Lubomir Bourdev et. Al inside Adobe Software Technology Lab that was
later include inside the Boost library distribution.

While sound and image manipulation are quite different, specially from
the psycho-perceptive point of view, they are both a signal processing
problem and thus share a lot in the representational issue. By
realising of a proper conceptual mapping between both worlds (table
\ref{tab:gilmap}), most of the library design and even quite a lot of
code of Boost.GIL can be reused to build a unique state-of-the-art
sound processing library that addresses the aforementioned issues in
an orthogonal generic manner while maintaining near-optimal
performance.

\begin{table}[h]
  \centering
  \begin{tabular}{c|c}
    Boost.GIL & Psynth.Sound \\ \hline\hline
    Channel   & Sample \\
    Color     & Channel \\
    Color Space & Channel Space \\
    Color Layout & Channel Layout \\
    Pixel & Frame \\
    View & Range \\
    Image & Buffer
  \end{tabular}
  \caption{Terminology map from \texttt{boost::gil} to \texttt{psynth::sound}}
  \label{tab:gilmap}
\end{table}

An \emph{image} is bidimensional matrix of \emph{pixels}, that capture
the properties of light electromagnetic waveform at those discrete
points. Each pixel, however, is decomposed in several \emph{colors}
that, for example, capture the intensity in the red, green and blue
sensors of a CCD camera. As there are different ways of decomposing an
audio frame (p.e, stereo, surround, etc.), there are different ways of
decomposing a pixel into several values, known as the \emph{color
  space} (p.e, RGB, CMYK, YUV, etc.). Boost.GIL uses the term
\emph{channel} to name the individual value of one those color
components.

In our audio framework, a \emph{buffer} is unidimensional array of
\emph{frames} that represent a sound or part of a sound --- sound is
continuous and thus we usually process it in chunks. The reader might
note that the the data in a buffer being arranged along the
\emph{time} dimension while the dimensions of an image represent
\emph{physical space} makes these entities completely different from
the processing point of view. However, they share most representation
problems, with sound representation being actually a sub-problem of
image representation, as we have one dimension less. The samples in a
series of audio frames can be stored in an interleaved or planar
fashion as happens with the channels of a pixel. Also, both channels
and samples can vary in signedness, fixed/floating point, bitdepth,
etc.

Those already familiar with Boost.GIL can thus already understand
easily our Psynth.Sound module design and implementation that we are
to describe in the following section.

\section{Design}

\subsection{Core techniques}

The Boost.GIL and thus the Psynth.Sound modules design makes heavy use
of static polymorphism and generic programming via C++ templates to
achieve generality without runtime overhead. We are going to introduce
advanced techniques used in generic programming for the reader
unfamiliar with this programming paradigm.

\subsubsection{Concepts}
\label{sec:concepts}.

\emph{Concepts} \cite{jarvi10concept} are to generic programming what
\emph{interfaces} --- pure abstract classes in C++ --- are to object
oriented programming: they specify the requirements on some
type. However there, are few substantial differences. (1) While
interfaces can only specify the method signatures of its instances, a
concept can specify most syntactic constraints on a type, like the
existence of free functions, operators, nested types, etc. (2) While
dispatching through interfaces requires, at least, a dereference,
addition and function call \cite{driesen96direct}, when using concepts
the concrete function to be executed can be determined and even
inlined at compile-time. (3) One can not declare that a type satisfies
an interface separately from the type definition, but one can say that
a type models a concept at any point of the program. (4) Thus, no
primitive type defines any virtual interface, but one can turn any
primitive type into an instance of any concept via a
\texttt{concept\_map}. (5) Actually, the syntactic properties defined
by a concept its models may differ, but they are matched via the
\texttt{concept\_map}. In fact, C++ concepts are more similar to
Haskell \emph{type classes}, with \texttt{instace} doing the job of
\texttt{concept\_map} \cite{bernardy08comparison}.

Concepts are an extension to the template mechanism to add type
checking for it. In fact, checking and dispatching on requirements can
be achieved with techniques like SFINAE (Substitution Failure Is Not
an Error) \cite{vandervoorde08templates}. Property (5) of our concepts
can be simulated with \emph{traits} \cite{c++traits}. However, both
compiler errors and the code using templates without concepts is
usually much more unreadable.

The proposal of adding concepts to the C++ language was rejected last
year by the standardisation committee and thus we can not use them in
our code. However, Boost.GIL is very influeced by Alexander Stepanov's
deductive approach to computer programming using generic programming
and modeling with concepts, that he elegantly describes in his
master-piece ``Elements of Programming''
\cite{stepanov09elements}. Actually Stepanov worked several years in
Adobe where he held a course ``Foundations of Programming'' based on
his book. Thus, the \emph{modeling} of the library extensively uses
concepts. Its implementation uses a limited form of concept checking
via the Boost.ConceptCheck\footnote{
  Boost.ConceptCheck: \url{http://www.boost.org/doc/libs/release/libs/concept_check/concept_check.htm}}
\cite{siek00concept} library, however, enabling this library in
release mode can affect performance and its syntax is quite more
cumbersome than the concepts in the C++ standard proposal. For
consistency with the Boost.GIL documentation we will use the concept
syntax proposed in the proposal N2081 to the standardisation committee
\cite{gregor06concept}.

The following example defines a concept that is satisfied by every
type that has an \texttt{operator<}:

\begin{lstlisting}
concept LessThanComparable<typename T> {
  bool operator< (T, T);
};
\end{lstlisting}

This allows us to write a generic function that depends on the
existence of a less-than comparator for the parametrised type:

\begin{lstlisting}
template<LessThanComparable T>
const T& min (const T& x, const T& y) {
  return x < y? x : y;
}
\end{lstlisting}

An alternative syntax for specifying that \texttt{T} must satisify the
\texttt{LessThanComparable} concept is the \texttt{where} clause:

\begin{lstlisting}
template<typename T>
    where LessThanComparable<T>
const T& min (const T& x, const T& y) ...
\end{lstlisting}

In fact, this is the only valid syntax when the concept affects
multiple types. Also, the \texttt{where} clause can be used inside
concept definitions to provide specialisation.

Specifying that a type models a concept is done with the
\texttt{concept\_map} device. If the type naturally models the
concept, we can just use:

\begin{lstlisting}
concept_map LessThanComparable<int> {}
\end{lstlisting}

Note that these trivial concept mappings can be avoided by using the
\texttt{auto} keyword in front of the \texttt{concept} keyword in the
concept definition. However, it might happen that a type requires some
wrapping to satisfy the concept. We can do this in the concept map
definition itself.

\begin{lstlisting}
concept_map LessThanComparable<char*> {
  bool operator< (char* a, char* b) {
    return strcmp (a, b) < 0;
  }
}
\end{lstlisting}

Note that this last piece of code is an example of a bad usage of
concept maps, as this specialises the mapping for pointers changing
the expected semantics.

This should suffice as an introduction to concepts in order to
understand the concept definitions that we will later show when
modelling our system. A more detailed view can be read in the cited
bibliography, with \cite{jarvi10concept} being the most updated and
useful from a programmer point of view.

\subsubsection{Metaprogramming}

The C++ template system is Turing complete
\cite{veldhuizen03templates}, thus it can be used to perform any
computation at \emph{compile time}. This was first noted in 1994 by
Erwin Unruh who, in the middle of a C++ standardisation committee,
wrote a template meta-program that outputted the first $N$ prime
numbers on the console using compiler errors \cite{unruh94prime}. Even
though this might seem just a crazy puzzle game, it can be used in
practise and actually new Boost libraries use it extensively. A very
gentle introduction to template metaprogramming can be found in
\cite{alexandrescu01modern}, where Alexandrescu uses them to
instantiate design patterns as generic C++ libraries. A deeper
reference is Abraham's \cite{abrahams04meta}, which focuses on the
Boost Metaprogramming Library\footnote{The Boost.MPL:
  www.boost.org/doc/libs/release/libs/mpl} and introduces the usage of
metaprogramming for building Embedded Domain Specific Languages (EDSL)
in C++. This Boost.MPL, providing reusable meta data structures and
algorithms, is the de-facto standard library for template
metaprogramming\footnote{It is often called ``the STL of template
  metaprogramming''.} and we will use it in our implementation.

Template metaprogramming is possible thanks to \emph{partial template
  specialisation}, that allows giving an alternate definition for a
pattern matched subset of its possible parameter values. A
\emph{metafunction} is thus just a template \texttt{class} or
\texttt{struct} with a public member that holds the result of the
function. It is up to the programmer to choose the naming convention
for the result members of the metafunctions, in the following, we will
use Abraham's style calling \texttt{type} for result values that are a
type, and \texttt{value} for integral values. Listing \ref{lst:fib}
illustrates how can we write and use a metafunction for computing the
$n$-th Fibonacci number.

\begin{lstlisting}[float=h!, 
  caption=Metaprogram for computing the Nth Fibonacci number,
  label=lst:fib]
template <int N>
struct fib {
  enum { 
    value = fib<N-1>::value + fib<N-2>::value; 
  };
};

template <>
struct fib <0> {
  enum { value = 0 };
};

template <>
struct fib <1> {
  enum { value = 1 };
};

int main () {
  return fib<42>::value;
}  
\end{lstlisting}

The program returns the forty-second Fibonacci value. However, it will
take no time to execute, because the number is computed at compile
time. We use recursion to define the metafunction for the general case
and the specialise for the base cases.

If we consider the template system as a meta-language on its own, we
should describe its most outstanding semantic properties. It is a pure
functional programming language, because variables are immutable. It
is lexically scoped. It supports both lazy and strict evaluation,
depending on whether we choose to access the nested \texttt{type}
result name at call site or value usage type. When we look at the meta
type system, we find three meta types: types (which are duck-typed
records), integrals (e.g. \texttt{int}, \texttt{char}, \texttt{bool}
...) and meta-functions (i.e. templates).

The fact that records are duck typed but integrals and metafunctions
cause several inconveniences in practice, specially when dealing with
the later. For example, in the absence of template aliases, returning
a metafunction produced by another function requires defining a nested
struct that inherits from the actual synthesised value. Also, the
template signature should be specified on a template parameter
expecting a template.

In order to simplify our meta type system we shall wrap constants in a
type like on listing \ref{lst:integral_c}.

\begin{lstlisting}[float, 
  caption=Integral constant nullary metafunction  wrapper.,
  label=lst:integral_c]
template <typename T, T V>
struct integral_c
{
  BOOST_STATIC_CONSTANT(T, value = V);
  typedef integral_c<T, V> type;
};
\end{lstlisting}

There are a couple of issues regarding this definition worth
explaining. First, the \texttt{BOOST\_STATIC\_CONSTANT} macro is used
to define a constant. Internally, it will try to use \texttt{enum} or
any other mechanism available to actually define the constant such
that the compiler is not tempted to allocate static memory for the
constant. Second, the \texttt{typedef} referring to itself turns a
constant value into a self returning nullary meta-function. This can
be very convenient because, for example, it allows using
\emph{value}\texttt{::type::value} always on the value usage point,
allowing the caller or producer of the value to choose whether he
wants to evaluate the value lazily.

Because we just wrapped values into a type, we can simplify our
conventional definition of \emph{metafunction}: a meta-function is any
type --- template or not --- that has a nested type called
\texttt{type}.

Now we should also turn metafunctions into first class entities of the
meta-language. We just add a new level of indirection and define a
\emph{metafunction class} as a type with a nested template
metafunction called \texttt{apply}. The example in listing
\ref{lst:high_order_fib} also illustrates the metafunction forwarding
technique when defining the nested \texttt{apply} metafunction by
inheriting from \texttt{fib}.

\begin{lstlisting}[float, caption=Metafunction class for
  computing Fibonacci numbers. We suppose that the previous
  \texttt{fib} definition uses \texttt{integral\_c} to wrap its
  parameters and return types., label=lst:high_order_fib]
struct fib_class { 
   template <class N>
   struct apply : public fib<N> {};
};

int main ()
{
  return fib_class::apply<integral_c<int, 42>>::type::value;
}
\end{lstlisting}

Using this convention the MPL library defines many useful high order
metafunctions that take metafunction classes as input, like
\texttt{mpl::fold} and \texttt{mpl::transform}. Note that it is not
needed to define metafunction classes for all our metafunctions,
instead, we shall convert them when needed using the
\texttt{mpl::quote}\emph{N} functions and the \texttt{mpl::lambda}
facility.

\subsection{Core concepts}

We are now ready to understand the main design and implementation
techniques used in our generic library. Because the library is
\emph{generic}, in the sense of generic programming, most algorithms
and data structures are parametrised such that they can be
instantiated with any concrete type modelling some concepts as we
suggested in section \ref{sec:concepts}. Thus, traditional modelling
techniques like the Unified Modelling Language are not useful since
they are intended for object oriented design.

We are going to follow the following methodology for describing the
library. First, we will name a concept and give a brief description of
its purpose. Then, we will define the concept using the notation
described in section \ref{sec:concepts} and finally we will enumerate
and describe some models for such concept.

For brevity, we will omit basic concepts such as
\texttt{CopyConstructible}, \texttt{Regular}, \texttt{Metafunction},
etc. Their complete definition should be evident and an interested
reader can find most of them in \cite{stepanov09elements}.

\subsubsection{\texttt{ChannelSpaceConcept}}

A channel space is a MPL sequence (like \type{mpl::list}) of whose
elements channel tags (empty types giving a name for the semantic
channel).

\begin{lstlisting}
concept ChannelSpaceConcept<MPLRandomAccessSequence Cs> 
{};
\end{lstlisting}

Some example models include \texttt{stereo\_space} or
\texttt{surround\_space}. An example on how a user of the library can
define his own channel space follows.

\begin{lstlisting}
struct left_channel {};
struct right_channel {};

typedef mpl::vector<left_channel, right_channel> stereo_space;
\end{lstlisting}

A related trivial concept is
\texttt{ChannelSpaceCompatibleConcept}. Two channel spaces are
compatible if they are the same. In fact, this leaks the underlying
MPL sequence type used in the channel space through the abstraction,
because spaces with the same set of semantic channels might be found
incompatible, but it suffices in practise.

\subsubsection{\type{SampleMappingConcept}}

An MPL Random Access Sequence, whose elements model
\texttt{MPLIntegralConstant} (like \texttt{mpl::int\_}) representing a
permutation of the channels in the channel space, thus specifying the
layout.

\begin{lstlisting}
concept SampleMappingConcept<MPLRandomAccessSequence CM> {
};
\end{lstlisting}

The \emph{layout} of a frame based type is a channel space plus a
sample mapping, as defined by:

\begin{lstlisting}
template <typename ChannelSpace,
	  typename SampleMapping = boost::mpl::range_c<
	      int, 0, boost::mpl::size<ChannelSpace>::value> >
struct layout
{
    typedef ChannelSpace   channel_space;
    typedef SampleMapping  sample_mapping;
};
\end{lstlisting}

The sample mapping is usually directly defined in the layout, if
needed at all --- the default sample mapping is the normal order in
the channel space. For example, the reversed stereo layout is defined
as:

\begin{lstlisting}
typedef layout<stereo_space, mpl::vector2_c<int, 1, 0>> rlstereo_layout;
\end{lstlisting}

\subsubsection{\texttt{SampleConcept}}

A \emph{sample} is the type we use to represent the amplitude of a
channel at certain point in time.

\begin{lstlisting}
concept SampleConcept<typename T> :
             EqualityComparable<T> {
    typename value_type      = T;
    // use sample_traits<T>::value_type to access it
    typename reference       = T&;
    // use sample_traits<T>::reference to access it
    typename pointer         = T*;
    // use sample_traits<T>::pointer to access it
    typename const_reference = const T&;
    // use sample_traits<T>::const_reference to access it
    typename const_pointer   = const T*;
    // use sample_traits<T>::const_pointer to access it
    static const bool is_mutable;
    // use sample_traits<T>::is_mutable to access it

    static T min_value(); 
    // use sample_traits<T>::min_value to access it
    static T zero_value(); 
    // use sample_traits<T>::zero_value to access it
    static T max_value(); 
    // use sample_traits<T>::min_value to access it
};
\end{lstlisting}

Built-in scalar types like \texttt{char}, \texttt{int} or
\texttt{float} model \texttt{SampleConcept} by default. 

The \texttt{scoped\_sample\_value<Type, Min, Max, Zero>} template
class models the concept whenever \texttt{Type} is a scalar type and
\texttt{Min}, \texttt{Zero} and \texttt{Max} satisfy:
\begin{equation}
Min < Zero < Max \land \forall x \in Type, x + Zero = x
\end{equation}
Note that, in order to avoid the limitation of floating point values
not being usable as template arguments, \texttt{Min}, \texttt{Zero}
and \texttt{Max} should be a type with a static method
\texttt{apply()} that returns the actual value. It should be used to
constraint the ``clipping thresholds'' of floating point types. For
example, the \texttt{bits32sf} model defined as:

\begin{lstlisting}
typedef scoped_sample<float,
                      float_minus_one,
                      float_zero,
                      float_one> bits32sf;
\end{lstlisting}

User defined types should specialise \texttt{sample\_traits} to map
the concept.

Related trivial concepts are \texttt{MutableSampleConcept} and
\texttt{SampleValueConcept} (a sample that is also \texttt{Regular}).

\subsubsection{\texttt{SampleConvertibleConcept}}

Because casting does not suffice in most cases, one should
override a \texttt{T sample\_convert (U)} function for \texttt{U} to
be convertible into \texttt{T}.

\begin{lstlisting}
concept SampleConvertibleConcept<SampleConcept SrcSample,
     SampleValueConcept DstSample> {
    DstSample sample_convert (const SrcSample&);
};
\end{lstlisting}

The library provides overrides for \texttt{sample\_convert} making
most supplied sample types being convertible too.

\subsubsection{\texttt{ChannelBaseConcept}}

A \emph{channel base} is a container of channel elements (such as
samples, sample references or sample pointers).

The most common use of channel base is in the implementation of a
frame, in which case the channel elements are sample values. The
channel base concept, however, can be used in other scenarios. For
example, a planar frame has samples that are not contiguous in
memory. Its reference is a proxy class that uses a channel base whose
elements are sample references. Its iterator uses a channel base whose
elements are sample iterators.

\begin{lstlisting}
concept ChannelBaseConcept<typename T> :
      CopyConstructible<T>, EqualityComparable<T>
{
    // a Psynth layout (the channel space and element permutation)
    typename layout;     
        
    // The type of K-th element
    template <int K> struct kth_element_type;
    where Metafunction<kth_element_type>;
    
    // The result of at_c
    template <int K> 
    struct kth_element_const_reference_type;
    where Metafunction<
            kth_element_const_reference_type>;        
    
    template <int K> 
    kth_element_const_reference_type<T,K>::type at_c(T);

    // Copy-constructible and equality comparable 
    // with other compatible channel bases
    template <ChannelBaseConcept T2> 
        where { ChannelBasesCompatibleConcept<T,T2> } 
        T::T(T2);
    template <ChannelBaseConcept T2> 
        where { ChannelBasesCompatibleConcept<T,T2> } 
        bool operator==(const T&, const T2&);
    template <ChannelBaseConcept T2> 
        where { ChannelBasesCompatibleConcept<T,T2> } 
        bool operator!=(const T&, const T2&);
};
\end{lstlisting}

A channel base must have an associated layout (which consists of a
channel space, as well as an ordering of the samples).  There are two
ways to index the elements of a channel base: A physical index
corresponds to the way they are ordered in memory, and a semantic
index corresponds to the way the elements are ordered in their channel
space.  For example, in the stereo channel space the elements are
ordered as \texttt{\{left\_channel, right\_channel\}}. For a channel
base with a RL-stereo layout, the first element in physical ordering
is the right element, whereas the first semantic element is the red
one.  Models of \texttt{ChannelBaseConcept} are required to provide
the \texttt{at\_c<K>(ChannelBase)} function, which allows for
accessing the elements based on their physical order. Psynth provides
a \texttt{semantic\_at\_c<K>(ChannelBase)} function (described
later) which can operate on any model of \texttt{ChannelBaseConcept}
and returns the corresponding semantic element.

A related concept is \texttt{MutableChannelBaseConcept} and
\texttt{ChannelBaseValueConcept} with the excepted definition. There
is also the concept \type{ChannelBasesCompatibleConcept}. Two channel
bases are compatible if they have the same channel space and their
elements are compatible, semantic-pairwise.

\subsubsection{\texttt{HomogeneousChannelBaseConcept}}

Channel base whose elements all have the same type.

\begin{lstlisting}
concept HomogeneousChannelBaseConcept<ChannelBaseConcept CB> {
    // For all K in [0 ... size<C1>::value-1):
    //     where SameType<kth_element_type<CB,K>::type,
    //                    kth_element_type<CB,K+1>::type>;    
    kth_element_const_reference_type<CB,0>::type dynamic_at_c(
           const CB&, std::size_t n) const;
};  
\end{lstlisting}

Related concepts \type{MutableHomogeneousChannelBaseConcept} and
\type{HomogeneousChannelBaseValueConcept} have the expected
definition.

The library provides an \texttt{homogeneous\_channel\_base} class that
models the concept.

\subsubsection{\texttt{FrameBasedConcept}}

Concept for all frame based constructs, such as frames themselves,
iterators, ranges and buffers whose value type is a frame. A
\texttt{FrameBased} type povides some metafunctions for accessing the
underlying channel space, sample mapping and whether the frame
representation is planar or interleaved.
  
\begin{lstlisting}
concept FrameBasedConcept<typename T> {
    typename channel_space_type<T>;     
        where Metafunction<channel_space_type<T> >;
        where ChannelSpaceConcept<channel_space_type<T>::type>;
    typename sample_mapping_type<T>; 
        where Metafunction<sample_mapping_type<T> >;  
        where SampleMappingConcept<sample_mapping_type<T>::type>;
    typename is_planar<T>;
        where Metafunction<is_planar<T> >;
        where SameType<is_planar<T>::type, bool>;
};  
\end{lstlisting}

There are many models for this in the library, like \type{buffer},
\type{buffer\_range}, \type{frame}, \type{bitaligned\_frame\_iterator},\\
\type{bitaligned\_frame\_reference}, \type{packed\_frame} and so on.

\subsubsection{\texttt{HomogeneousFrameBasedConcept}}

Concept for homogeneous frame-based constructs --- frame based with
the same sample type for all its channels. These should allow access
to the underlying sample type.

\begin{lstlisting}
concept HomogeneousFrameBasedConcept<FrameBasedConcept T> {
    typename sample_type<T>;         
        where Metafunction<sample_type<T> >;
        where SampleConcept<sample_type<T>::type>;
};
\end{lstlisting}

Most container and alike constructs in the library --- iteators,
buffers, ranges --- model this whenever the underlying frame is
homogeneous.

\subsubsection{\texttt{FrameConcept}}

A set of samples coincident in time, one per channel in the given
channel space.

\begin{lstlisting}
concept FrameConcept<typename F> :
            ChannelBaseConcept<F>, FrameBasedConcept<F> {    
    where is_frame<F>::type::value==true;
    // where for each K [0..size<F>::value-1]:
    //      SampleConcept<kth_element_type<F,K> >;
        
    typename F::value_type;       where FrameValueConcept<value_type>;
    typename F::reference;        where FrameConcept<reference>;
    typename F::const_reference;  where FrameConcept<const_reference>;
    static const bool F::is_mutable;

    template <FrameConcept F2> where { FrameConcept<F,F2> } 
        F::F(F2);
    template <FrameConcept F2> where { FrameConcept<F,F2> } 
        bool operator==(const F&, const F2&);
    template <FrameConcept F2> where { FrameConcept<F,F2> } 
        bool operator!=(const F&, const F2&);
}; 
\end{lstlisting}

Related concepts are \type{MutableFrameConcept} and
\type{FrameValueConcept}, defined as usually.

Frame compatibility should be tested with the
\texttt{FramesCompatibleConcept}.  Frames are compatible if their
samples and channel space types are compatible. Compatible frames can
be assigned and copy constructed from one another.


Provided models include \type{frame}, \type{packed\_frame},
\type{planar\_frame\_reference} and
\type{bit\_aligned\_frame\_reference}.

\subsubsection{\texttt{HomogeneousFrameConcept}}

A frame with all samples of the same type should also provide an
indexed access operator.

\begin{lstlisting}
concept HomogeneousFrameConcept<FrameConcept P> :
   HomogeneousChannelBaseConcept<P>, HomogeneousFrameBasedConcept<P> { 
     P::template element_const_reference_type<P>::type operator[] (
          P p, std::size_t i) const { return dynamic_at_c(p,i); }
};
\end{lstlisting}

Related concepts are \type{MutableHomogeneousFrameConcept} and
\type{HomogeneousFrameValueConcept}, defined as usually.

Provided models include \type{planar\_frame\_reference} and
\type{frame}.

\subsubsection{\texttt{FrameConvertibleConcept}}

A frame type is convertible to another frame type if there exist a
\texttt{channel\_convert} overload. Convertibility is non-symmetric
and implies that one frame can be converted to another, approximating
the value. Conversion is explicit and sometimes lossy.

\begin{lstlisting}
template <FrameConcept SrcFrame, MutableFrameConcept DstFrame>
concept FrameConvertibleConcept {
    void channel_convert(const SrcFrame&, DstFrame&);
};
\end{lstlisting}

Frame types provided by the library are convertible.

\subsubsection{\texttt{FrameDereferenceAdaptorConcept}}

Represents a unary function object that can be invoked upon
dereferencing a frame iterator. This can perform an arbitrary
computation, such as channel conversion or table lookup.

\begin{lstlisting}
concept FrameDereferenceAdaptorConcept<boost::UnaryFunctionConcept D>
  : DefaultConstructibleConcept<D>, base::CopyConstructibleConcept<D>,
    AssignableConcept<D>  {
    typename const_type;
        where FrameDereferenceAdaptorConcept<const_t>;
    typename value_type;
        where FrameValueConcept<value_type>;
    typename reference;         // may be mutable
    typename const_reference;   // must not be mutable
    static const bool D::is_mutable;

    where Convertible<value_type,result_type>;
};
\end{lstlisting}

The \type{channel\_convert\_deref\_fn} provides a model that performs
channel conversion.

\subsubsection{\texttt{FrameIteratorConcept}}

An STL random access traversal iterator over a model of
\type{FrameConcept}. Our iterators must provide some extra
metafunctions.

\begin{lstlisting}
concept FrameIteratorConcept<typename Iterator> :
boost_concepts::RandomAccessTraversalConcept<Iterator>,
FrameBasedConcept<Iterator> {
    where FrameValueConcept<value_type>;
    typename const_iterator_type<It>::type;         
        where FrameIteratorConcept<const_iterator_type<It>::type>;
    static const bool  iterator_is_mutable<It>::type::value;          
    static const bool  is_iterator_adaptor<It>::type::value;
    // is it an iterator adaptor
};
\end{lstlisting}

Related concepts include \type{MutableFrameIteratorConcept}, defined
as usually. The related \texttt{HasDynamicStepTypeConcept} is modelled
by those iterator types with an overload for the
\type{dynamic\_step\_type} metafunction returning a similar iterator
that models \texttt{StepIteratorConcept}.

Models include \type{T*} where \type{T} is a frame or
\type{bitaligned\_frame\_iterator},
\texttt{memory\_based\_step\_iterator} and
\type{planar\_frame\_iterator}.

\subsubsection{\texttt{MemoryBasedIteratorConcept}}

Iterator that advances by a specified step. Concept of a random-access
iterator that can be advanced in memory units (bytes or bits).

\begin{lstlisting}
concept MemoryBasedIteratorConcept<
          boost_concepts::RandomAccessTraversalConcept Iterator> {
    typename byte_to_memunit<Iterator>;
    where metafunction<byte_to_memunit<Iterator> >;
    std::ptrdiff_t memunit_step(const Iterator&);
    std::ptrdiff_t memunit_distance(const Iterator& , const Iterator&);
    void memunit_advance(Iterator&, std::ptrdiff_t diff);
    Iterator memunit_advanced(const Iterator& p,
    std::ptrdiff_t diff)
    { Iterator tmp; memunit_advance(tmp,diff); return tmp; }
    Iterator::reference memunit_advanced_ref(
    const Iterator& p, std::ptrdiff_t diff) 
    { return *memunit_advanced(p,diff); }
};
\end{lstlisting}

Iterators defined by our library are memory based.

\subsubsection{StepIteratorConcept}

Step iterators are iterators that have can be set a step that skips
elements.

\begin{lstlisting}
concept StepIteratorConcept<
        boost_concepts::ForwardTraversalConcept Iterator> {
    template <Integral D> void Iterator::set_step(D step);
};
\end{lstlisting}

A related \type{MutableStepIteratorConcept} is defined as expected.
The class \type{memory\_based\_step\_iterator} models the concept.

\subsubsection{FrameIteratorConceptIteratorAdaptorConcept}

Iterator adaptor is a forward iterator adapting another forward
iterator.

\begin{lstlisting}
concept IteratorAdaptorConcept<
            boost_concepts::ForwardTraversalConcept Iterator> {
    where SameType<is_iterator_adaptor<Iterator>::type, boost::mpl::true_>;

    typename iterator_adaptor_get_base<Iterator>;
        where Metafunction<iterator_adaptor_get_base<Iterator> >;
        where boost_concepts::ForwardTraversalConcept<
                  iterator_adaptor_get_base<Iterator>::type>;
    
    typename another_iterator; 
    typename iterator_adaptor_rebind<Iterator,another_iterator>::type;
        where boost_concepts::ForwardTraversalConcept<another_iterator>;
        where IteratorAdaptorConcept<iterator_adaptor_rebind<
                 Iterator,another_iterator>::type>;

    const iterator_adaptor_get_base<Iterator>::type&
    Iterator::base() const;
};
\end{lstlisting}

There exist a related \type{MutableIteratorAdaptorConcept} with the
usual definition. Classes \type{dereference\_iterator\_adaptor} and
\type{memory\_based\_step\_iterator} do model the concept.

\subsubsection{RandomAccessBufferRangeConcept}

This is a range, similar to the new STL range defined in C++0x, but
with some extra members for random access.

\begin{lstlisting}
concept RandomAccessBufferRangeConcept<base::Regular Range> {
    typename value_type;
    typename reference;       // result of dereferencing
    typename difference_type;
    // result of operator-(iterator,iterator)
    typename const_type; where RandomAccessBufferRangeConcept<Range>;
    // same as Range, but over immutable values
    typename iterator; where RandomAccessTraversalConcept<iterator>;
    // iterator over all values
    typename reverse_iterator;
    where RandomAccessTraversalConcept<reverse_iterator>; 
    typename size_type;       // the return value of size()

    // Defines the type of a range similar to this type, except it
    // invokes Deref upon dereferencing
    template <FrameDereferenceAdaptorConcept Deref>
    struct add_deref {
        typename type;
        where RandomAccessBufferRangeConcept<type>;
        static type make(const Range& v, const Deref& deref);
    };
    
    // Create from a locator at the top-left corner and dimensions
    Range::Range(const locator&, const point_type&);
    
    // total number of elements
    size_type        Range::size()       const; 
    reference        operator[](Range, const difference_type&) const;
    
    iterator         Range::begin()      const;
    iterator         Range::end()        const;
    reverse_iterator Range::rbegin()     const;
    reverse_iterator Range::rend()       const;
    iterator         Range::at(const point_t&);

    reference operator()(Range,const point_t&) const;
};
\end{lstlisting}

There exists a \type{MutableRandomAccessBufferRange} with the usual
semantics.

\subsubsection{BufferRangeConcept}

A random access range over frames, it has extra information to get the
number of channels of the underlying frame type.

\begin{lstlisting}
concept BufferRangeConcept<RandomAccessBufferRangeConcept Range> 
{
    where FrameValueConcept<value_type>;
    std::size_t Range::num_channels() const;
};
\end{lstlisting}

There exists a related \type{MutableBufferRangeConcept} with the
expected definition. Also, there is a
\type{RangesAreCompatibleConcept}. Ranges are compatible if they have
the same channel spaces and compatible sample values. Constness and
layout are not important for compatibility.

The library provides the
\texttt{buffer\_range<Iterator>} model.

\subsubsection{RandomAccessBufferConcept}

A container of values. The values are accessible via an associated
range. Buffers are not ranges by themselves, because that generates
boilerplate due to constness problems --- a \type{const} range may
give mutable access to its frames, but a \type{const} buffer does
not, thus an algorithm that may mutate the frames but not the range
would have to provide two overloads.

\begin{lstlisting}
concept RandomAccessBufferConcept<typename Buf> : 
            base::Regular<Buf> {
    typename range; where MutableRandomAccessBufferRangeConcept<range>;
    typename const_range = range::const_type;
    typename value_type  = range::value_type;
    typename allocator_type;

    Buf::Buf(point_t dims, std::size_t alignment=1);
    Buf::Buf(point_t dims, value_type fill_value, std::size_t alignment);
    
    void Buf::recreate(point_t new_dims, std::size_t alignment=1);
    void Buf::recreate(point_t new_dims, value_type fill_value,
                       std::size_t alignment);
    
    const const_range_t&   const_range(const Buf&);
    const range_t&         range(Buf&);
};
\end{lstlisting}

\subsubsection{BufferConcept}

A buffer containing frames.

\begin{lstlisting}
concept BufferConcept<RandomAccess2DBufferConcept Buf> {
    where MutableBufferRangeConcept<range_t>;
};
\end{lstlisting}

The \type{buffer} models the concept.

\subsubsection{RingBufferRangeConcept}

\todo{Define}

\subsubsection{RingBufferConcept}

\todo{Define}

\subsection{Going dynamic}
\subsection{Input and Output module}
\subsection{Synthesis module}

\section{Validation}

\subsection{Unit testing}

Unit testing serves to ensure that the actual behaviour of a function
matches its documented requirements. In this code it is very important
because: (1) because it is a library to be used by third party
developers, the proper functioning of every single method is as
important as the observable behaviour of the final application that we
may deploy alongside; and (2) because of the duck typing in template
metaprograms we need to ensure that all ``instantiation paths'' ---
i.e. code paths of the metaprogram --- compile without errors and lead
to correct execution.

\todo{Recordar actualizar esto si más adelante se añaden pruebas por
  lo que sea} The modules described in this chapter are evaluated with
a total 223 unit tests. All of them pass with a total of 1478
successful assertions. Note \ref{note:gistests} includes a more
detailed summary of the test cases involving these modules. Not all of
those unit tests have been written manually. Using
\type{BOOST\_UNIT\_TEST\_TEMPLATE} once can define a parametrised over
a type and that is later instantiated for every type in a given MPL
sequence. For example, we can compute the product of a MPL sequence of
buffer types with a metafunction and pass the result to the templated
unit test that checks proper conversion among buffer types,
simplifying a lot the amount of testing code --- avoiding
combinatorial explosion of code to test all instantiation paths.

\begin{mynote}[\texttt{psynth::sound} and \texttt{psynth::io} unit
  tests]
\label{note:gistests}
The user can run the unit tests by herself by running \texttt{make
  check} or running the \texttt{psynth\_unit\_tests} in the
\texttt{src/test} folder.
{\small
\begin{verbatim}
Test suite "io_input_test_suite" passed with:
  177 assertions out of 177 passed
  110 test cases out of 110 passed

Test suite "io_output_test_suite" passed with:
  140 assertions out of 140 passed
  81 test cases out of 81 passed

Test suite "sound_ring_test" passed with:
  10 assertions out of 10 passed
  4 test cases out of 4 passed

Test suite "frame_iterator_test_suite" passed with:
  5 assertions out of 5 passed
  2 test cases out of 2 passed

Test suite "sound_peformance_test_suite" passed 
with:
  38 assertions out of 38 passed
  4 test cases out of 4 passed

Test suite "buffer_test_suite" passed with:
  14 assertions out of 14 passed
  2 test cases out of 2 passed

Test suite "sound_frame_test_suite" passed with:
  81 assertions out of 81 passed
  4 test cases out of 4 passed

Test suite "sound_sample_test_suite" passed with:
  1073 assertions out of 1073 passed
  14 test cases out of 14 passed
\end{verbatim}
}
\end{mynote}

\subsection{Performance}

We claimed that static polymorphism and optimal algorithm selection
via template metaprogramming allow genericity with no overhead over
non-generic implementations. Given the performance constraints on the
real time audio processing thread, satisfying this property is a must.

To ensure that there is no overhead, we include a test suite that
compares the efficiency of the generic algorithm building blocks
provided by the library with hand-rolled loops performing the same
function. Listing \ref{lst:perf-gen} shows an example of such generic
function that you can compare with its concrete implementation in
\ref{lst:perf-nongen}. Note that for simplicity and because it does
not affect the results the non generic version is still parametrised
over the sample type $T$. One can read the whole performance test
suite in \texttt{src/test/psynth/sound/performance.cpp}.

\begin{lstlisting}[float=h,
  caption={Generic \texttt{for\_each} that asigns $(0,1)$ to every
  frame over non interleaved data},
  label=lst:perf-gen]
for_each_frame (_v, [] (F& f) { 
    f = F {0, 1};
});
\end{lstlisting}

\begin{lstlisting}[float=h,
  caption={Non generic \texttt{for\_each} that asigns $(0,1)$ to every
  frame over non interleaved data},
  label=lst:perf-nongen]
T* first = (T*)_v.begin ();
T* last  = first + _v.size () * 2;
while (first != last) {
    first [0] =  0;
    first [1] =  1;
    first     += 2;
}
\end{lstlisting}

We check the performance on some different cases that try to stress
different potential overhead corners, like using a different layout
from the natural order in the channel space, planar and interleaved
buffers, etc. Each test case test a kind of loop over a buffer of a
certain size. We test sizes of 32 and 4092 samples, as those are the
common bounds of buffer sizes used in audio (the lower the buffer
size, the better ---lower--- latency). This way we ensure that both
the per buffer and per sample overhead is minimal. Each test is
repeated $2^{21}$ times for buffers with 4096 samples, and $2^{26}$
times for buffers of 32 samples.

\begin{table}[h!]
  \centering\small
  \begin{tabular}{rl}
    Name & Meaning \\ \hline
    \type{s8b} & Interleaved stereo buffer with 8 bit samples.\\
    \type{rs8b} & Interleaved reversed stereo buffer with 8 bit samples.\\
    \type{s8pb} & Planar stereo buffer with 8 bit samples.\\
    \type{s8f} & Stereo frame with 8 bit samples.\\
    \type{rs8f} & Reversed stereo frame with 8 bit samples.\\
  \end{tabular}
  \caption{Acronyms for the parameter types in performance test result
    tables.}
  \label{tab:perfacrn}
\end{table}

We ran the tests in a Intel i5 M460 with four 2.53FHz cores. We
compiled tested the code with different versions of GCC compiled with
options \texttt{-O3 -std=c++0x}. Tables \ref{tab:perf4096} and
\ref{tab:perf32} show the results for GCC 4.5.2 with 4096 and 32
buffer size respectively and \ref{tab:perf4096-46} and
\ref{tab:perf32-46} show the results for GCC 4.6.0. The acronyms for
the concrete parameter types are expanded in table \ref{tab:perfacrn}

The tables show interesting results. With GCC 4.5 the generic versions
performs as efficiently or better most of the time for larger buffer
sizes, however, there seems to be an additive constant that makes the
hand coded version slightly better when the buffer size is very
small. Surprisingly, GCC 4.6 changes this tendency and the generic
version actually gets more favourable results with short buffer
sizes. Actually the results are more even with this compiler in a
probable tendency in making optimisation techniques more general ---
i.e. dependent on the actual semantics of the code and not on
how you express it --- which is very desirable for generic code.

In any case, these results supports our claims that the performance
overhead, if any, is negligible. Sometimes the generic code is even
more efficient than a carefully hand-coded algorithm for a specific
audio format. The results also show that as soon as you add arithmetic
computations like in the \texttt{transform} test micro-optimisation in
the looping constructs is futile. Maybe testing with a wider variety
of compilers should be done, but that is not possible because few
support C++0x. Anyway, it is to expect that a compiler supporting
C++0x also has a decent optimiser and the we would get similar
results. Comparison of the generated object code would can be another
interesting mechanism for assuring the lack of overhead due to
generality. We did informal tests confirming our hypotheses that can
be repeated by the reader. Also, there are some similar object code
comparisons in the Boost.GIL video tutorial\footnote{Boost.GIL
  presentation:
  \url{http://stlab.adobe.com/gil/presentation/index.htm}} that the
interested reader can check --- given the similarities in GIL and
\texttt{psynth::sound} we can expect equivalent results.

We can safely state that the library passes the performance requirements.

\begin{table}[p]
  \centering\small
  \begin{tabular}{c|c|c|c|c|c}
    Algo. & \multicolumn{2}{c|}{Parameters} & Psynth & Non-Psynth & Gain \\ \hline\hline

    %% fill_frames
    \multirow{4}{*}{\type{fill}} & \multirow{2}{*}{\type{s8b}} & \type{s8f} & 0.38147 & 0.38147 & 1 \\ 
    &  & \type{rs8f} & 0.376701 & 0.38147 & 1.0127 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8f} & 0.195503 & 0.190735 & 0.9756 \\
    &  & \type{rs8f} & 0.190735 & 0.190735 & 1 \\ \hline

    %% for_each_frame
    \multirow{2}{*}{\type{for\_each}} & \multicolumn{2}{c|}{\type{s8b}} & 0.371933 & 0.376701 & 1.0128 \\
    & \multicolumn{2}{c|}{\type{s8pb}} & 0.286102 & 0.281334 & 0.9833 \\ \hline
    
    %% copy_frames
    \multirow{5}{*}{\type{copy}} & \multirow{3}{*}{\type{s8b}} & \type{s8b} & 0.38147 & 0.38147 & 1 \\ 
    &  & \type{rs8b} & 1.00136 & 1.05381 & 1.0524 \\ 
    &  & \type{s8pb} & 0.753403 & 0.753403 & 1 \\ 
    & \multirow{2}{*}{\type{s8pb}} & \type{s8pb} & 0.748634 & 0.762939 & 1.0191 \\ 
    &  & \type{s8b} & 0.38147 & 0.38147 & 1 \\ \hline

    %% transform_frames
    \multirow{4}{*}{\type{transform}} & \multirow{2}{*}{\type{s8b}} & \type{s8b} & 23.4795 & 23.4842 & 1.0002 \\ 
    &  & \type{s8pb} & 23.4842 & 23.4842 & 1 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8b} & 23.4842 & 23.4842 & 1 \\
    &  & \type{s8pb} & 23.4842 & 23.4842 & 1 \\ \hline
  \end{tabular}
  \caption{Performance tests  4096 buffer size with GCC 4.5.}
  \label{tab:perf4096}
\end{table}

\begin{table}[p]
  \centering\small
  \begin{tabular}{c|c|c|c|c|c}
    Algo. & \multicolumn{2}{c|}{Parameters} & Psynth & Non-Psynth & Gain \\ \hline\hline

    %% fill_frames
    \multirow{4}{*}{\type{fill}} & \multirow{2}{*}{\type{s8b}} & \type{s8f} & 0.0103563 & 0.0104308 & 1.0071 \\ 
    &  & \type{rs8f} & 0.0103563 & 0.0104308 & 1.0071 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8f} & 0.0125915 & 0.0104308 & 0.8284 \\
    &  & \type{rs8f} & 0.018999 & 0.0139326 & 0.7333 \\ \hline

    %% for_each_frame
    \multirow{2}{*}{\type{for\_each}} & \multicolumn{2}{c|}{\type{s8b}} & 0.00149012 & 0.00141561 & 0.9499 \\
    & \multicolumn{2}{c|}{\type{s8pb}} & 0.0090152 & 0.0064075 & 0.7107 \\ \hline

    %% copy_frames
    \multirow{5}{*}{\type{copy}} & \multirow{3}{*}{\type{s8b}} & \type{s8b} & 0.012517 & 0.012219 & 0.9761 \\ 
    &  & \type{rs8b} & 0.0112504 & 0.0108033 & 0.9602 \\ 
    &  & \type{s8pb} & 0.0179559 & 0.0175089 & 0.9751 \\ 
    & \multirow{2}{*}{\type{s8pb}} & \type{s8pb} & 0.0239909 & 0.0243634 & 1.0155 \\ 
    &  & \type{s8b} & 0.0136346 &  0.00394881 & 0.2896 \\ \hline

    %% transform_frames
    \multirow{4}{*}{\type{transform}} & \multirow{2}{*}{\type{s8b}} & \type{s8b} & 0.183433 & 0.183508 & 1.0004 \\ 
    &  & \type{s8pb} & 0.183508 & 0.183433 & 0.9995\\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8b} & 0.183433 & 0.183508 & 1.0004 \\
    &  & \type{s8pb} & 0.183508 & 0.183433 & 0.9995 \\ \hline
  \end{tabular}
  \caption{Performance tests for 32 buffer size with GCC 4.5.}
  \label{tab:perf32}
\end{table}

\begin{table}[p]
  \centering\small
  \begin{tabular}{c|c|c|c|c|c}
    Algo. & \multicolumn{2}{c|}{Parameters} & Psynth & Non-Psynth & Gain \\ \hline\hline

    %% fill_frames
    \multirow{4}{*}{\type{fill}} & \multirow{2}{*}{\type{s8b}} & \type{s8f} & 0.557899 & 0.562668 & 1.0085 \\ 
    &  & \type{rs8f} & 0.557899 & 0.557899 & 1 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8f} & 0.190735 & 0.190735 & 1 \\
    &  & \type{rs8f} & 0.190735 & 0.185966 & 0.9749 \\ \hline

    %% for_each_frame
    \multirow{2}{*}{\type{for\_each}} & \multicolumn{2}{c|}{\type{s8b}} & 0.557899 & 0.562668 & 1.0085 \\
    & \multicolumn{2}{c|}{\type{s8pb}} & 0.276566 & 0.286102 & 1.0344 \\ \hline
    
    %% copy_frames
    \multirow{5}{*}{\type{copy}} & \multirow{3}{*}{\type{s8b}} & \type{s8b} & 0.739098 & 0.743866 & 1.0064 \\ 
    &  & \type{rs8b} & 1.05381 & 0.934601 & 0.8868 \\ 
    &  & \type{s8pb} & 0.753403 & 0.753403 & 1 \\ 
    & \multirow{2}{*}{\type{s8pb}} & \type{s8pb} & 0.867844 & 0.743866 & 0.8571 \\ 
    &  & \type{s8b} & 0.38147 & 0.386238 & 1.0125 \\ \hline

    %% transform_frames
    \multirow{4}{*}{\type{transform}} & \multirow{2}{*}{\type{s8b}} & \type{s8b} & 23.4842 & 23.4795 & 0.9997 \\ 
    &  & \type{s8pb} & 23.4842 & 23.4842 & 1 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8b} & 23.4842 & 23.4842 & 1 \\
    &  & \type{s8pb} & 23.4842 & 23.4795 & 0.9997 \\ \hline
  \end{tabular}
  \caption{Performance tests for 4096 samples with GCC~4.6.}
  \label{tab:perf4096-46}
\end{table}

\begin{table}[p]
  \centering\small
  \begin{tabular}{c|c|c|c|c|c}
    Algo. & \multicolumn{2}{c|}{Parameters} & Psynth & Non-Psynth & Gain \\ \hline\hline

    %% fill_frames
    \multirow{4}{*}{\type{fill}} & \multirow{2}{*}{\type{s8b}} & \type{s8f} & 0.00625849 & 0.00625849 & 1 \\ 
    &  & \type{rs8f} & 0.00499189 & 0.00499189 & 1 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8f} & 0.0103563 & 0.0104308 & 1.0071 \\
    &  & \type{rs8f} & 0.0104308 & 0.0104308 & 1 \\ \hline

    %% for_each_frame
    \multirow{2}{*}{\type{for\_each}} & \multicolumn{2}{c|}{\type{s8b}} & 0.00618398 & 0.00625849 & 1.0120 \\
    & \multicolumn{2}{c|}{\type{s8pb}} & 0.0064075 & 0.0064075 & 1 \\ \hline

    %% copy_frames
    \multirow{5}{*}{\type{copy}} & \multirow{3}{*}{\type{s8b}} & \type{s8b} & 0.012219 & 0.0125915 & 1.0304 \\ 
    &  & \type{rs8b} & 0.00782311 & 0.0111014 & 1.419 \\ 
    &  & \type{s8pb} & 0.0169873 & 0.0172853 & 1.018 \\ 
    & \multirow{2}{*}{\type{s8pb}} & \type{s8pb} & 0.0243634 & 0.0219047 & 0.899 \\ 
    &  & \type{s8b} & 0.0114739 &  0.0160933 & 1.4026 \\ \hline

    %% transform_frames
    \multirow{4}{*}{\type{transform}} & \multirow{2}{*}{\type{s8b}} & \type{s8b} & 0.183433 & 0.183508 & 1.0004 \\ 
    &  & \type{s8pb} & 0.183433 & 0.183582 & 1.0004 \\
    & \multirow{2}{*}{\type{s8pb}} & \type{s8b} & 0.183433 & 0.183433 & 1 \\
    &  & \type{s8pb} & 0.183433 & 0.183508 & 1.0004 \\ \hline
  \end{tabular}
  \caption{Performance tests for 32 buffer size with GCC 4.6.}
  \label{tab:perf32-46}
\end{table}

\subsection{Integration}

The module was first developed separately from the main development
branch in a branch called \texttt{gil-import}. Once the previous tests
were passed, the former signal representation classes and I/O code was
removed from the code base. The upper layers --- mainly the
\texttt{graph} layer --- was adapted to use the new library. Note
that, given that we will mostly rewrite the \texttt{graph} layer in
the next iteration we tried to make minimal changes to get the project
compile and run properly again.

The system was then \emph{peer reviewed} by project collaborators,
mainly by the maintainer of the Ubuntu/Trinux packages Aleksander
Morgado\footnote{Aleksander Morgado's web blog:
  \url{http://sigquit.wordpress.com}}. After minor bugfixing, we
agreed to make a new Psychosynth 0.2.0 release that included the new
code described in this chapter and some other fixes and modifications
developed alongside.

The official changelog briefing for this release is included in note
\ref{note:changelog02}.

\begin{mynote}[Changelog of Psychosynth 0.2.0]
\label{note:changelog02}
\begin{itemize}
\item New audio processing and I/O subsystem based on template programming
for generic yet efficient sound signals.

\item The extreme latency when using ALSA bug seems to be fixed in
  some cases.

\item No longer depend on libvorbis, libsndfile can now handle ogg and flac
files too.

\item No longer depend on \texttt{libsigc++}, using \texttt{boost::signals}
  which, which is a bit slower but neglibe and this simplifies the
  dependencies.

\item The mouse wheel now scrolls in the object selector.

\item The object selector no longer lets mouse clicks pass through.  

\item Backwards reproducing a sample works a bit better now too.

\item Some new niceties in the framework base layer, including some
  experiments on applying the C3 class linearisation algorithm in raw
  C++.

\item C++0x features are being used in the code. For GCC, this means
  version 4.5 shall be used. We doubt it will compile with any other
  compiler (maybe latest VS), but users are welcomed to try and report.

\item For this same reason, Boost.Threads is no longer a dependency,
  we use STL threads instead.
\end{itemize}
\end{mynote}

\section{Conclusions}

In this iteration we developed a generic approach to representation
and input and output of audio data. We do not have any records of
any audio software using such paradigm in their code, so this
development have been exploratory and has a lot of value in its
novelty. This however delayed our development more than expected in
our original plan.

\subsection{Benefits and caveats}

The three main advantages in the new code are:
\begin{enumerate}
\item Code can be mostly abstracted from the audio format
  representation while retaining near optimal performance. Because
  generality allowed decoupling orthogonal concepts, each audio
  representation factor can be optimised and tuned for computational
  accuracy on its own, leading to higher quality code with lower
  maintenance cost as we avoid the combinatorial explosion that
  happens otherwise.

\item Algorithms correctly written with our generic facilities have a
  performance equivalent to the hand-written code. When a certain
  algorithm has not general interpretation or can not be efficiently
  implemented generally, the library still allows for the algorithm to
  be written with for a concrete or a constrained family of audio
  formats.

\item Because the signal format is encoded in the data type, we can
  either statically check that the data is in the correct format
  through our processing chain, or trivially enforce runtime checks
  when the format is unknown at compile time (via
  \texttt{dynamic\_buffer} and similar tools), leading to more secure
  code.
\end{enumerate}

Also, because a lot of learning have happened since the old code base
was written, the new code is better written and quite safer, making
use of exceptions and scope guards \cite{alexandrescu00gener}.

Even though we believe the benefits outweight the drawbacks, we have
to acknowledge the caveats of our new approach, the most relevant
being:

\begin{enumerate}
\item The new code uses advanced C++ programming techniques that many
  programmers find hard to understand. Thus, it might be harder for
  casual contributors to join the project in the future.

\item In the absence of real language support for concepts, template
  metaprograms leak their implementation in user code's compilation
  errors. This is so because, actually, by expanding the type
  instantiations in the compilation error, the compiler is actually
  showing a full backtrace of the metaprogram. This leads to cryptic
  error messages that often obfuscate the real source of the problem,
  discouraging novel developers.

\item Template metaprograms take longer to compile. However, proper
  usage of the new \texttt{extern template} facility should avoid
  redundantly instantiating templates in different translation units
  only to be discarded by the linker mostly solving this issue. Also,
  because the compiler generates different object code for each audio
  format, thoughtless use of the library can lead to code bloat and
  too large binary size.
\end{enumerate}

\subsection{Future work}

While the current status of the library is quite satisfactory for our
needs, there is still a lot of room for improvement that we will
postpone since they fall outside this project's scope. Nonetheless it
is worth enumerating them:

\subsubsection{Lock free ring buffers}

\todo{No se que mejor paper citar sobre la inversión de
  prioridades. El que he puesto es reciente y no muy original pero
  parece de los más orientados a nuestro tipo de trabajo y de hecho
  introduce el tema de los bufferes lock-free}

The audio processing thread has real time constraints. As we
introduced in note \ref{note:realtime} this implies, among other
things, forbidding the usage of mutexes. However, our ring buffers
have not been tested for thread safety and mutexes should be used when
shared among different threads. This happens in our
\texttt{caching\_file\_input} implementation. The problem is specially
severe when the audio processing thread is running with higher priority,
because \emph{priority inversion} occurs \cite{kim03basic}. While our
current Alsa and OSS output systems do not attempt rising their thread
priority, the Jackd subsystem executes the audio processing callback
in a real-time mode thread and thus the problem can become significant.

Locking is done with care and in practice we have experience no buffer
underruns due to this problem, even with high number of caching file
readers in execution.  However, for correctness and better support of
Jackd, we should implement a lock-free ring buffer
\cite{valois94lock}\cite{michael95correction} that does not require
using special synchronisation. Jackd actually provides a C
implementation that can serve as a basis for ours. The most important
interface change is that only one reader should be permitted --- we
can embed the read pointer inside the data structure. Also, the
``backwards'' operation mode in our current implementation might
introduce an unexpected complexity in the implementation.

\subsubsection{Virtual and adapted iterators and ranges}

Boost.GIL included a ``locator adapter'' and ``virtual locator''
notions that allowed creating or modifying images lazily via a
function object. We discarded implementing the virtual ones because
they were coupled to their \texttt{locator} concept which is specific
to the problem of image representation --- locators are in practice 2D
iterators. Moreover, they used the indexed position in the image as
the parameter to the function object that synthesised the
image. However, because audio is processed in chunks, the position in
the audio buffer is meaningless for the synthesis or filter function
--- instead, some stateful function object which includes a notion of
time position related to the frame rate is needed. Thus, many
unexplored design decisions should be taken, and the interactions with
other similar libraries like Boost.Iterator\footnote{The
  Boost.Iterator Library:
  \url{http://www.boost.org/doc/libs/release/libs/iterator}} and
Boost.Range\footnote{The Boost.Range Library:
  \url{http://www.boost.org/doc/libs/release/libs/range}} should be
carefully evaluated.

\subsubsection{Better arithmetic support}

The library includes some basic arithmetic support for samples. There
are few complications when developing full generic arithmetic support
for samples and frames. As Lubomir Bourdev, lead developer of
Boost.GIL, stated it in an email conversation with us:

\begin{quotation}
``Doing arithmetic operations is tricky for a number of reasons:

\begin{itemize}
\item What do you do on overflow? Clip, throw exception, allow out of
  range values?

\item What is the type to be used during conversion? Even if the
  source and destination have the same type, the operation might need
  to be done in another type and then cast back.

\item Certain arithmetic operations have no meaningful interpretation
  as far as color is concerned, such as multiplying one pixel by
  another. 
\end{itemize}

Because of issues like these we have not tackled the problem of
providing arithmetic operations, but we have provided generic
operations that can be done per channel or per pair of channels which
could be the basis for arithmetic operations.''
\end{quotation}

Nonetheless with time and effort the problem could be
approached making some compromises. Some of the issues Lubomir states
have different answers for sound processing, in fact, allowing out of
range values is the best answer for the first question given the fact
that sound amplitude is not naturally constrained and clipping is
introduced only by the DAC hardware or when moving from floating to a
fixed point representation. Maybe, not all those questions have to be
answered in order to improve the arithmetic support.

One of the main annoyances when writing a generic algorithm is using
the per sample \texttt{static\_*} algorithms. Using them we could
write a simple arithmetic layer for frames that would simplify the
user code. However, even though we do not have experimental data, we
believe this straightforward solution could introduce overhead. This
is because every \texttt{static\_*} unrolls one statement per
channel. Thus, a simple frame arithmetic expression would in fact
result into many sequence points that is yet to be tested whether
compilers can optimise properly.

This is not a dead end. Using the \emph{expressions templates}
\cite{veldhuizen95expression} technique and r-value references we can
perform transformations with the aid of metaprogramming such that
sequence points are not introduced by the arithmetic expression
itself. A expression template framework like Boost.Proto\footnote{The
  Boost Proto library:
  \url{http://www.boost.org/doc/libs/release/libs/proto}}
\cite{niebler07proto} could be of great help. Moreover, with careful
studying of the audio DSL's studied in section \ref{sec:dsl} and the
usage of these same techniques the scope of such effort could be
broadened to build a full sound synthesis and processing EDSL for C++.

\subsubsection{Submission to Boost}

In our conversations with Lubomir Bourdev he suggested submitting our
library for inclusion in the Boost package. However, there are few
issues that we should tackle before that:

\begin{enumerate}
\item A lot of code is algorithmically identical to that of Boost.GIL
  with changes only in terminology. A lot of work in properly
  abstracting such common parts should be made to avoid code
  repetition and doubled maintenance effort inside Boost.

\item As we said earlier, interesting interactions can emerge with
  the Boost.Iterator and Boost.Range libraries. We believe that any
  possible issues and unneeded incompatibilities with those libraries
  should be solved before submission into Boost.

\item Boost is written in C++03 standard, while our code uses
  C++0x. Moreover, our code has dependencies with other submodules in
  \texttt{psynth::base}, specially the expection and logging
  system. While these dependencies are not too strong, the effort made
  to polish these corners is outside the scope of the current project.
\end{enumerate}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "00-main"
%%% End: 
